searchNodes=[{"doc":"Documentation for Tokenizers .","ref":"Tokenizers.html","title":"Tokenizers","type":"module"},{"doc":"Decode the given list of ids or list of lists of ids back to strings.","ref":"Tokenizers.html#decode/2","title":"Tokenizers.decode/2","type":"function"},{"doc":"Encode the given sequence or batch of sequences to ids.","ref":"Tokenizers.html#encode/2","title":"Tokenizers.encode/2","type":"function"},{"doc":"Instantiate a new tokenizer from the file at the given path.","ref":"Tokenizers.html#from_file/1","title":"Tokenizers.from_file/1","type":"function"},{"doc":"Instantiate a new tokenizer from an existing file on the Hugging Face Hub.","ref":"Tokenizers.html#from_pretrained/1","title":"Tokenizers.from_pretrained/1","type":"function"},{"doc":"Get the ids from an encoding.","ref":"Tokenizers.html#get_ids/1","title":"Tokenizers.get_ids/1","type":"function"},{"doc":"Get the tokens from an encoding.","ref":"Tokenizers.html#get_tokens/1","title":"Tokenizers.get_tokens/1","type":"function"},{"doc":"Get the tokenizer's vocabulary as a map of token to id.","ref":"Tokenizers.html#get_vocab/1","title":"Tokenizers.get_vocab/1","type":"function"},{"doc":"Get the number of tokens in the vocabulary.","ref":"Tokenizers.html#get_vocab_size/1","title":"Tokenizers.get_vocab_size/1","type":"function"},{"doc":"Convert a given id to its token.","ref":"Tokenizers.html#id_to_token/2","title":"Tokenizers.id_to_token/2","type":"function"},{"doc":"Save the tokenizer to the provided path.","ref":"Tokenizers.html#save/2","title":"Tokenizers.save/2","type":"function"},{"doc":"Convert a given token to its id.","ref":"Tokenizers.html#token_to_id/2","title":"Tokenizers.token_to_id/2","type":"function"},{"doc":"","ref":"Tokenizers.Encoding.html","title":"Tokenizers.Encoding","type":"module"},{"doc":"","ref":"Tokenizers.Encoding.html#t:t/0","title":"Tokenizers.Encoding.t/0","type":"type"},{"doc":"","ref":"Tokenizers.Native.html","title":"Tokenizers.Native","type":"module"},{"doc":"","ref":"Tokenizers.Native.html#decode/3","title":"Tokenizers.Native.decode/3","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#decode_batch/3","title":"Tokenizers.Native.decode_batch/3","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#encode/3","title":"Tokenizers.Native.encode/3","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#encode_batch/3","title":"Tokenizers.Native.encode_batch/3","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#from_file/1","title":"Tokenizers.Native.from_file/1","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#from_pretrained/1","title":"Tokenizers.Native.from_pretrained/1","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#get_ids/1","title":"Tokenizers.Native.get_ids/1","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#get_tokens/1","title":"Tokenizers.Native.get_tokens/1","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#get_vocab/2","title":"Tokenizers.Native.get_vocab/2","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#get_vocab_size/2","title":"Tokenizers.Native.get_vocab_size/2","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#id_to_token/2","title":"Tokenizers.Native.id_to_token/2","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#save/3","title":"Tokenizers.Native.save/3","type":"function"},{"doc":"","ref":"Tokenizers.Native.html#token_to_id/2","title":"Tokenizers.Native.token_to_id/2","type":"function"},{"doc":"","ref":"Tokenizers.Tokenizer.html","title":"Tokenizers.Tokenizer","type":"module"},{"doc":"","ref":"Tokenizers.Tokenizer.html#t:t/0","title":"Tokenizers.Tokenizer.t/0","type":"type"}]